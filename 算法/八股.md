# c语言

## 1. 柔性数组

    在linux中一些结构体中可以看到这样的定义

```c
struct vring_avail {
    __virtio16 flags;
    __virtio16 idx;
    __virtio16 ring[];
};
```

   可以看到这里的ring数组是没有长度的，这个就是柔性数组，柔性数组在没有分配内存的时候不占内存的，例如

```c
#include<stdio.h>

struct vring
{
        int num;
        int a[];
};

int main()
{
        int n=sizeof(struct vring);
        printf("%d\r\n",n);
        return 0;
}
```

    这里sizeof打印出来只有4，是num的大小，如果要给数组分配大小这样分配

```c
struct vring *v = malloc(sizeof(struct vring) + 10 * sizeof(int));
```

    注意声明柔性数组只能在结构体的最后声明

[C语言0长度数组(可变数组/柔性数组)详解_零长数组使用-CSDN博客](https://blog.csdn.net/gatieme/article/details/64131322)

# 操作系统

## 1.大页

    正常来说我们的页表管理的最小单位是4k。如果某个业务恒定的需要大内存或者对延迟较敏感的场景，可以使用大页机制。

    以四级页表为例，我们可以在第三级或者第二级中就引出pte，假如在第二级页表中引出，一个页的大小就是1G，从三级页表中引出，一个页大小就是2MB。

    那么这个时候就有人要问了，主播主播大页有什么好处，为什么要开大页，用4kb不行吗？这个问题可以从以下几个方面来考虑

    1）同样使用1GB的物理内存，如果使用传统页表，我们就会有1GB / 4KB = 262144页，每个pte占8b，那么pte就要占262144×8B=2MB，再加上三级页表的页目录项，大约就是2mb，但是用1GB大页就只用8b，如果在物理内存特别大的机器上使用大页，就可以省下很多内存了。

    2）

# 其他

## 1.cache一致性以及MESI协议

    cache是cpu和内存的中介，在有了cache之后，cpu的读写数据都走cache，不直接和内存交互。在单核系统下，cpu要读数据时，会从内存中读取想读的数据和附近的数据（一致性原理）读到cache中，cpu再从cache中拿；同理cpu要写数据时也是先将新数据写到cache中（如果cache中没有该数据，就先读再写），再更新到内存中。这在单核场景下看起来并没有问题，但是如果是多个cpu，同时读取了数据a=0，cpu1想更改a+=1，更改完之后并没有写回到内存中，此时cpu2也想更改a+=1，本来这两波操作下来a应该是2，但是这样操作a就是1了，明显有问题。

    对于cpu写数据有两种写回方法：

    1）写直达：这种方法可以保证cache与内存的一致性，在cpu写数据的时候，同时把数据写入cache和内存中，但是这种方法会频繁的写内存，性能肯定不佳

    2）写回：如果想要提升性能，肯定要想办法尽可能少的写内存，具体策略是这样的。如果要更新数据时，该数据还在cache中，则把该部分cache标记为dirty，说明cache和内存是不一致的；如果该数据对应的cache block已经被替换掉了，就看替换掉的数据是不是dirty的，如果是就把这个数据写回到内存里去，再把要写的数据写入到到这个cache block，吧之前那个数据替换掉，如果替换的数据不是dirty，那就直接覆盖。总之：当前写的数据永远不会写回，写回的只是替换了原本写的数据的位置数据（为dirty情况下）。

    

    为了解决上面说到的问题就要保证两点：

    1）当某个cpu cache数据更新时，必须要传播到其他cpu 的cache中去，这个叫写传播

    2）某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串形化

    第二点说的是，假如abcd cache上同时有变量x，初始都为0，a和b同时修改x=100和x=200，在写传播过程中，c可能先看到x=100再看到x=200，那么c就认为c=200，但是d先看到x=200再看到x=100，d就认为d=100。所以就有问题。    

    所以在写传播的过程中，需要拿“锁”，保证其他cpu cache看到的更新顺序一定是相同的

### MESI协议

    MESI协议说的是四个状态：标记 Cache Line 四个不同的状态

+ Modified 已修改：脏标记，已经修改了cache中的数据但是没有同步到内存中

+ Exclusive 独占： Cache Block 里的数据是干净且这个数据里只有当前cpu cache中存在，更改之后可以不通知其他cpu

+ Shared 共享：Cache Block 里的数据是干净且其他cpu cache中也有这个数据，如果更改了必须通知其他cpu。

+ Invalidated 已失效：通过总线嗅探发现cache发现这个 Cache Block已经被更改了，不可以读取这个数据

    这个就是整个状态机的状态转移图，其实这里主要解决两个问题：一个是上面说的事物串型化问题，还有一个就是不用在每次更新数据都让发送给其他cpu，让其他cpu一直检测这个状态，优化了这个过程。

![](assets/83eed2eca91abc39f0cf0468f683b073c638c80d.png)



    一些其他cache的知识：cache的组织方式是以cache cline的形式组织的，在cpu发现cache中没有想要的数据时，会从内存中读，不只是读自己想要的数据，而是一次读一批数据，这一批数据就是一个cache cline。从局部性原理来看，读的这一批cache cline就是要读的数据和这个数据之后的一些数据。

    那么问题来了，同样是遍历一个数组，这两种方式的访问速度又区别吗？

    因为第一种的访问在内存排布上来看是连续的，所以更容易被cache命中，第二种的两次内存访问存在跨度，所以可能出现cache 命中率低的情况，所以第一种运行起来会比第二种要快

![](assets/0cc5425afa6170abe1f890eab5721d62f6bc9e06.png)

## 关于锁的知识

### 各种锁的区别

    最底层的是自选锁和互斥锁，当有一个进程加锁的时候，另一个进程尝试加锁就会失败，失败后的操作就是自选锁和互斥锁的区别。

+ 自旋锁在加锁失败之后，线程就会忙等待，直到他拿到锁

+ 互斥锁加锁失败之后，就会睡眠（schedule主动调度出去），等待下一次唤醒再尝试拿锁

    互斥锁在加锁失败时，由于需要schedule，所以会从用户态陷入到内核态，让内核去切换线程，会增加性能的开销。

    而自旋锁

    为什么自旋锁的实现形式就是while循环去等待锁，但是如果等的太久，时间片被用完之后还不会被切换出去？因为申请自旋锁的时候preempt_disable关了抢占，哪怕时间片用完，也也只会设置 TIF_NEED_RESCHED，而不会立即调用 schedule()。当拿到锁之后才会打开抢占。

### 信号量和锁的区别

    实际上是互斥与同步概念的区别

    乐观锁与悲观锁？

## 优先级翻转问题
