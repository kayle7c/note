# c语言

## 1. 柔性数组

    在linux中一些结构体中可以看到这样的定义

```c
struct vring_avail {
    __virtio16 flags;
    __virtio16 idx;
    __virtio16 ring[];
};
```

   可以看到这里的ring数组是没有长度的，这个就是柔性数组，柔性数组在没有分配内存的时候不占内存的，例如

```c
#include<stdio.h>

struct vring
{
        int num;
        int a[];
};

int main()
{
        int n=sizeof(struct vring);
        printf("%d\r\n",n);
        return 0;
}
```

    这里sizeof打印出来只有4，是num的大小，如果要给数组分配大小这样分配

```c
struct vring *v = malloc(sizeof(struct vring) + 10 * sizeof(int));
```

    注意声明柔性数组只能在结构体的最后声明

[C语言0长度数组(可变数组/柔性数组)详解_零长数组使用-CSDN博客](https://blog.csdn.net/gatieme/article/details/64131322)

# 操作系统

## 1.大页

    正常来说我们的页表管理的最小单位是4k。如果某个业务恒定的需要大内存或者对延迟较敏感的场景，可以使用大页机制。

    以四级页表为例，我们可以在第三级或者第二级中就引出pte，假如在第二级页表中引出，一个页的大小就是1G，从三级页表中引出，一个页大小就是2MB。

    那么这个时候就有人要问了，主播主播大页有什么好处，为什么要开大页，用4kb不行吗？这个问题可以从以下几个方面来考虑

    1）同样使用1GB的物理内存，如果使用传统页表，我们就会有1GB / 4KB = 262144页，每个pte占8b，那么pte就要占262144×8B=2MB，再加上三级页表的页目录项，大约就是2mb，但是用1GB大页就只用8b，如果在物理内存特别大的机器上使用大页，就可以省下很多内存了。

    2）

# 其他

## 1.cache一致性以及MESI协议

    cache是cpu和内存的中介，在有了cache之后，cpu的读写数据都走cache，不直接和内存交互。在单核系统下，cpu要读数据时，会从内存中读取想读的数据和附近的数据（一致性原理）读到cache中，cpu再从cache中拿；同理cpu要写数据时也是先将新数据写到cache中（如果cache中没有该数据，就先读再写），再更新到内存中。这在单核场景下看起来并没有问题，但是如果是多个cpu，同时读取了数据a=0，cpu1想更改a+=1，更改完之后并没有写回到内存中，此时cpu2也想更改a+=1，本来这两波操作下来a应该是2，但是这样操作a就是1了，明显有问题。

    对于cpu写数据有两种写回方法：

    1）写直达：这种方法可以保证cache与内存的一致性，在cpu写数据的时候，同时把数据写入cache和内存中，但是这种方法会频繁的写内存，性能肯定不佳

    2）写回：如果想要提升性能，肯定要想办法尽可能少的写内存，具体策略是这样的。如果要更新数据时，该数据还在cache中，则把该部分cache标记为dirty，说明cache和内存是不一致的；如果该数据对应的cache block已经被替换掉了，就看替换掉的数据是不是dirty的，如果是就把这个数据写回到内存里去，再把要写的数据写入到到这个cache block，吧之前那个数据替换掉，如果替换的数据不是dirty，那就直接覆盖。总之：当前写的数据永远不会写回，写回的只是替换了原本写的数据的位置数据（为dirty情况下）。

    

    为了解决上面说到的问题就要保证两点：

    1）当某个cpu cache数据更新时，必须要传播到其他cpu 的cache中去，这个叫写传播

    2）某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串形化

    第二点说的是，假如abcd cache上同时有变量x，初始都为0，a和b同时修改x=100和x=200，在写传播过程中，c可能先看到x=100再看到x=200，那么c就认为c=200，但是d先看到x=200再看到x=100，d就认为d=100。所以就有问题。    

    所以在写传播的过程中，需要拿“锁”，保证其他cpu cache看到的更新顺序一定是相同的

### MESI协议

    MESI协议说的是四个状态：标记 Cache Line 四个不同的状态

+ Modified 已修改：脏标记，已经修改了cache中的数据但是没有同步到内存中

+ Exclusive 独占： Cache Block 里的数据是干净且这个数据里只有当前cpu cache中存在，更改之后可以不通知其他cpu

+ Shared 共享：Cache Block 里的数据是干净且其他cpu cache中也有这个数据，如果更改了必须通知其他cpu。

+ Invalidated 已失效：通过总线嗅探发现cache发现这个 Cache Block已经被更改了，不可以读取这个数据

    这个就是整个状态机的状态转移图，其实这里主要解决两个问题：一个是上面说的事物串型化问题，还有一个就是不用在每次更新数据都让发送给其他cpu，让其他cpu一直检测这个状态，优化了这个过程。

![](assets/83eed2eca91abc39f0cf0468f683b073c638c80d.png)

    一些其他cache的知识：cache的组织方式是以cache cline的形式组织的，在cpu发现cache中没有想要的数据时，会从内存中读，不只是读自己想要的数据，而是一次读一批数据，这一批数据就是一个cache cline。从局部性原理来看，读的这一批cache cline就是要读的数据和这个数据之后的一些数据。

    那么问题来了，同样是遍历一个数组，这两种方式的访问速度又区别吗？

    因为第一种的访问在内存排布上来看是连续的，所以更容易被cache命中，第二种的两次内存访问存在跨度，所以可能出现cache 命中率低的情况，所以第一种运行起来会比第二种要快

![](assets/0cc5425afa6170abe1f890eab5721d62f6bc9e06.png)

## 关于锁的知识

    首先明确一点，锁的存在是为了保护共享变量，是为了防止多个线程操作同一个变量，造成数据不一致的问题。可以理解为机组学过的：写后读，读后写，写后写问题。如果你发现同时有多个线程会操作（读/写）同一个变量的时候，就要提高警惕，考虑要不要用锁。

### 各种锁的区别

#### 自旋锁和互斥锁

    最底层的是自选锁和互斥锁，当有一个进程加锁的时候，另一个进程尝试加锁就会失败，失败后的操作就是自选锁和互斥锁的区别。

+ 自旋锁在加锁失败之后，线程就会忙等待，直到他拿到锁

+ 互斥锁加锁失败之后，就会睡眠（schedule主动调度出去），等待下一次唤醒再尝试拿锁

    互斥锁在加锁失败时，由于需要schedule，所以会从用户态陷入到内核态，让内核去切换线程，会增加性能的开销。

    而自旋锁使用CAS（cmpxchg原子操作），在用户态完成加锁和解锁操作，不会主动产生线程上下文切换



    ps1：用户态自旋锁有两种：
    1）：纯用户态自旋锁（pthread_spinlock_t等），由glibc提供的
    2）：内核提供的futex

    ps2：内核态：为什么自旋锁的实现形式就是while循环去等待锁，但是如果等的太久，时间片被用完之后还不会被切换出去？因为申请自旋锁的时候preempt_disable关了抢占，哪怕时间片用完，也也只会设置 TIF_NEED_RESCHED，而不会立即调用 schedule()。当拿到锁之后才会打开抢占。

```c
void __lockfunc __raw_##op##_lock(locktype##_t *lock)            \
{                                    \
    for (;;) {                            \
        preempt_disable();                    \
        if (likely(do_raw_##op##_trylock(lock)))        \
            break;                        \
        preempt_enable();                    \
                                    \
        arch_##op##_relax(&lock->raw_lock);            \
    }                                \
}                                    \
```

    ps3：单核场景下自旋锁是没有意义的，只有一个核你自选等待，是指望谁给你释放锁呢？

    之前面试官问过我一个问题：在提及自旋锁的时候我说自选锁是忙等待，面试官就问我说忙等待指的是什么，我说是while(1)一直等待直到锁释放为止（那个时候其实我没有搞清楚用户态的自旋锁和内核态的自选锁的区别），他就问我那你用户态写一个while（1）难道会说卡死在这里吗？ 确实给我问住了，既然是在用户态执行的代码只要你 不陷入内核态，就不可能做到一直保持running状态，但是如果能被调度出去那为什么叫自选锁，只是主动睡眠和被动睡眠的区别，意义在哪？

    解答：
    1）忙等待在这里要区分场景来看：如果是内核的自选锁，忙等待就是真正while（1），因为这里是关了抢占的。为什么要关抢占?如果不关抢占在拿到锁之后被切出去，这里临界区执行不完释放不了锁，会导致锁竞争恶化，不如把抢占关了，尽快执行完临界区的好释放锁；如果是用户态的自选锁，忙等待就不是真正的while（1）了，在时间片耗尽时，依然会被调度出去。（其实这里的while1是pause指令，理解为低功耗模式吧～）

    2）在用户态也会被调度出去的自选锁 意义在哪？因为互斥锁的schedule是有代价的，代价就是两次切换上下文的消耗，而spinlock的代价就是等待前面释放锁的时间，所以你要算一笔账，到底是 mutex两次消耗大还是等待这个锁消耗的时间大。在锁竞争激烈的情况下可以使用mutex，不激烈的情况下使用spinlock。

 

#### 读写锁

    读写锁将读写分开了，读资源用读锁，写资源用写锁。在没有写的情况下，多个线程可以并发持有读锁去读取。但是有写锁时，读线程获取锁的操作会被阻塞，并且其他写进程也会被阻塞。任何时候只能有一个进程拿读锁。在读多写少的场景下可以发挥优势。

    按照优先级可以被分为

### 信号量和锁的区别

    实际上是互斥与同步概念的区别

    乐观锁与悲观锁？

## 优先级翻转问题
